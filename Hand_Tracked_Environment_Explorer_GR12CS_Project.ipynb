{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rohaaq/Grade-12-CS-Project-AR-Brick-Breaker-/blob/main/Hand_Tracked_Environment_Explorer_GR12CS_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KNwPPbeF9KE"
      },
      "source": [
        "# Misc Block W/ Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JtqW3QM9H8y0",
        "outputId": "f617562e-0914-42ab-84e6-3b329786e232",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (23.2.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.3.7)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.23)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.23+cuda12.cudnn89)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.25.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from mediapipe) (2.2.1+cu121)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.8.0.76)\n",
            "Requirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.20.3)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.4.6-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.16.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (1.11.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->mediapipe) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->mediapipe) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->mediapipe) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->mediapipe) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->mediapipe) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->mediapipe) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->mediapipe)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->mediapipe)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->mediapipe)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch->mediapipe)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch->mediapipe)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch->mediapipe)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch->mediapipe)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch->mediapipe)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch->mediapipe)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch->mediapipe)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch->mediapipe)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->mediapipe) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->mediapipe)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->mediapipe) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->mediapipe) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, sounddevice, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, mediapipe\n",
            "Successfully installed mediapipe-0.10.11 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 sounddevice-0.4.6\n"
          ]
        }
      ],
      "source": [
        "# Installing Libraries in case stuff doesn't work\n",
        "!pip install mediapipe\n",
        "#!pip install google\n",
        "#!pip install google.colab.output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEcDRgR6-O3d"
      },
      "outputs": [],
      "source": [
        "# Rohaan Haq\n",
        "# Final CS project\n",
        "# See Requirnments and Design doc. Will use handtracking to navigate a virtual enviorment\n",
        "# Should be noted: I did initally refrence some of Adrian's mouse script whe starting this project\n",
        "\n",
        "#Resource and To-Do List Page:\n",
        "# https://docs.google.com/document/d/1-7RL2OQmJxO8wAYxSy-9iKUawdRrw2bgDn-mXoUEqMo/edit#\n",
        "\n",
        "#Libraries\n",
        "\n",
        "# Lib's for webcam\n",
        "from IPython.display import Image\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "#Lib's for Hand tracking\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "import time\n",
        "import cv2\n",
        "\n",
        "# Grid Libraries\n",
        "from google.colab import output\n",
        "import random\n",
        "\n",
        "#prints out info about parameters\n",
        "#help(mp.solutions.hands.Hands)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwuxGIt7GFsb"
      },
      "source": [
        "#Module 1: Hand tracking & Output Movment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LsBJ6h2PQls"
      },
      "outputs": [],
      "source": [
        "# Helper Functions\n",
        "\n",
        "# function to convert the JavaScript object into an OpenCV image\n",
        "# Taken from this project (https://colab.research.google.com/drive/1xdjyBiY75MAVRSjgmiqI7pbRLn58VrbE?usp=sharing#scrollTo=xZk68RUQW3Xq)\n",
        "def js_to_image(js_image):\n",
        "\n",
        "  # decode base64 image\n",
        "  image_bytes = b64decode(js_image.split(',')[1])\n",
        "  # convert bytes to numpy array\n",
        "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "  # decode numpy array into OpenCV BGR image\n",
        "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "\n",
        "  return img\n",
        "\n",
        "\n",
        "# Function for handling the diplay of webcam (uses JavaScript)\n",
        "# Also taken from above project. I did my best to comment but idk exactly what all this does.\n",
        "# ALso has various helper functions\n",
        "def video_stream():\n",
        "  js = Javascript('''\n",
        "    //Variables\n",
        "      var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "    var labelElement;\n",
        "\n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "\n",
        "    // Removes frame, I think?\n",
        "    function removeDom() {\n",
        "       stream.getVideoTracks()[0].stop();\n",
        "       video.remove();\n",
        "       div.remove();\n",
        "       video = null;\n",
        "       div = null;\n",
        "       stream = null;\n",
        "       imgElement = null;\n",
        "       captureCanvas = null;\n",
        "       labelElement = null;\n",
        "    }\n",
        "\n",
        "    // I'm honestly not sure\n",
        "    function onAnimationFrame() {\n",
        "      if (!shutdown) {\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "      }\n",
        "      if (pendingResolve) {\n",
        "        var result = \"\";\n",
        "        if (!shutdown) {\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
        "        }\n",
        "        var lp = pendingResolve;\n",
        "        pendingResolve = null;\n",
        "        lp(result);\n",
        "      }\n",
        "    }\n",
        "\n",
        "    // Initalizes window\n",
        "    // Should prob revisit this for un-mirroring feed\n",
        "    async function createDom() {\n",
        "      if (div !== null) {\n",
        "        return stream;\n",
        "      }\n",
        "\n",
        "      div = document.createElement('div');\n",
        "      div.style.border = '2px solid black';\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '600px';\n",
        "      document.body.appendChild(div);\n",
        "\n",
        "      const modelOut = document.createElement('div');\n",
        "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
        "      labelElement = document.createElement('span');\n",
        "      labelElement.innerText = 'No data';\n",
        "      labelElement.style.fontWeight = 'bold';\n",
        "      modelOut.appendChild(labelElement);\n",
        "      div.appendChild(modelOut);\n",
        "\n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      video.width = div.clientWidth - 6;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { shutdown = true; };\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\n",
        "          {video: { facingMode: \"environment\"}});\n",
        "      div.appendChild(video);\n",
        "\n",
        "      imgElement = document.createElement('img');\n",
        "      imgElement.style.position = 'absolute';\n",
        "      imgElement.style.zIndex = 1;\n",
        "      imgElement.onclick = () => { shutdown = true; };\n",
        "      div.appendChild(imgElement);\n",
        "\n",
        "      // Feed caption\n",
        "      const instruction = document.createElement('div');\n",
        "      instruction.innerHTML =\n",
        "          '<span style=\"color: red; font-weight: bold;\">' +\n",
        "          'When finished, click here or on the video to stop this demo</span>';\n",
        "      div.appendChild(instruction);\n",
        "      instruction.onclick = () => { shutdown = true; };\n",
        "\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      captureCanvas = document.createElement('canvas');\n",
        "      captureCanvas.width = 640; //video.videoWidth;\n",
        "      captureCanvas.height = 480; //video.videoHeight;\n",
        "      window.requestAnimationFrame(onAnimationFrame);\n",
        "\n",
        "      return stream;\n",
        "    }\n",
        "    // Condition for stoping stream\n",
        "    async function stream_frame(label, imgData) {\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "      // Main logoic\n",
        "      var preCreate = Date.now();\n",
        "      // Creating window\n",
        "      stream = await createDom();\n",
        "\n",
        "      var preShow = Date.now();\n",
        "      if (label != \"\") {\n",
        "        labelElement.innerHTML = label;\n",
        "      }\n",
        "\n",
        "      if (imgData != \"\") {\n",
        "        var videoRect = video.getClientRects()[0];\n",
        "        imgElement.style.top = videoRect.top + \"px\";\n",
        "        imgElement.style.left = videoRect.left + \"px\";\n",
        "        imgElement.style.width = videoRect.width + \"px\";\n",
        "        imgElement.style.height = videoRect.height + \"px\";\n",
        "        imgElement.src = imgData;\n",
        "      }\n",
        "\n",
        "      var preCapture = Date.now();\n",
        "      var result = await new Promise(function(resolve, reject) {\n",
        "        pendingResolve = resolve;\n",
        "      });\n",
        "      shutdown = false;\n",
        "\n",
        "      return {'create': preShow - preCreate,\n",
        "              'show': preCapture - preShow,\n",
        "              'capture': Date.now() - preCapture,\n",
        "              'img': result};\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "  display(js)\n",
        "\n",
        "#Gets the current video frame, and labels it\n",
        "def video_frame(label, bbox):\n",
        "  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n",
        "  return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZMuqLyBz3Fc",
        "outputId": "83dec282-83f1-4691-bded-c65568fe4bde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " +  +  +  +  +  +  +  +  +  +  +  +  +  +  +  + \n",
            " +  +  +  +  + ▉ +  +  +  + ▉ +  +  +  +  + \n",
            " +  +  +  +  +  +  +  +  +  +  +  +  +  +  +  + \n",
            " +  +  +  +  +  +  + ▉ +  +  +  +  +  +  +  + \n",
            " +  +  +  🎉  +  +  +  +  +  +  +  +  +  +  +  + \n",
            " + ▉ +  +  +  +  +  +  +  +  +  +  +  +  +  + \n",
            " +  +  +  +  +  +  +  +  +  +  +  + ▉ +  +  + \n",
            " +  +  +  +  + ▉ +  +  +  +  +  +  +  +  + ▉\n",
            " +  +  + ▉ +  +  +  +  +  +  +  +  +  +  +  + \n",
            " +  +  +  +  +  +  +  +  +  +  +  +  +  +  +  + \n",
            " + ▉ +  +  +  +  +  +  + ▉ +  +  + ▉▉ + \n",
            " +  +  +  +  +  +  +  +  +  +  +  +  + ▉ +  + \n",
            " +  +  + ▉ +  +  +  +  +  +  +  +  +  +  +  + \n",
            " +  +  +  +  +  +  +  +  + ▉ +  +  +  +  +  + \n",
            " +  +  +  +  +  +  +  +  +  +  +  +  + ▉ +  + \n",
            " +  +  +  +  +  +  +  +  +  + ▉ +  +  +  +  + \n"
          ]
        }
      ],
      "source": [
        "# Functions and code for ASCII Maze\n",
        "\n",
        "#Holds the previous postion of the player. Global for use in functions\n",
        "past_x = 1\n",
        "past_y = 1\n",
        "\n",
        "#print(past_x, past_y)\n",
        "\n",
        "# Creates a 2D array to store grid\n",
        "#grid_size = input(\"Grid size please? /n\")\n",
        "grid_size = 16\n",
        "maze = [[\" + \" for i in range(grid_size+1)] for i in range(grid_size+1)]\n",
        "\n",
        "#Function for printing grid. Concatonates the elements from each row\n",
        "def maze_print(maze):\n",
        "    for i in range(len(maze)-1):\n",
        "        line = \"\"\n",
        "        for j in range(len(maze[i])-1):\n",
        "            line += maze[i][j]\n",
        "        print(line)\n",
        "#print(maze)\n",
        "\n",
        "#Creates n number random obstacles and puts them in grid\n",
        "num_blocks  = 20\n",
        "while num_blocks:\n",
        "    num_blocks -= 1\n",
        "    maze[random.randint(1, grid_size)][random.randint(1, grid_size)] = \"▉\"\n",
        "\n",
        "# Updates grid to place postion of current\n",
        "def update_maze(x_pos, y_pos):\n",
        "    # Clears past grid\n",
        "    output.clear()\n",
        "\n",
        "    global past_x\n",
        "    global past_y\n",
        "\n",
        "    # Puts empty tile back where user was last turn (if here was a last turn)\n",
        "    if past_x != None and past_y != None:\n",
        "        maze[past_x][past_y] = \" + \"\n",
        "    # Puts player tile on current postion\n",
        "    maze[x_pos][y_pos] = \" 🎉 \"\n",
        "\n",
        "    # Sets past position to current position\n",
        "    past_x = x_pos\n",
        "    past_y = y_pos\n",
        "\n",
        "    maze_print(maze)\n",
        "\n",
        "    # Some experimental code that doesn't quite work yet. Rather than a maze, the game is to try to remove all the blocks\n",
        "    \"\"\"\n",
        "    # Removes block if player is on it\n",
        "    if maze[x_pos][y_pos] == \"▉\":\n",
        "        num_blocks -= 1\n",
        "\n",
        "        # Win message if all blocks are gone\n",
        "        if num_blocks == 0:\n",
        "            print(\"You Won!\")\n",
        "\n",
        "        #Updates and prints block\n",
        "        else:\n",
        "    \"\"\"\n",
        "#Testing output\n",
        "update_maze(4, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 983
        },
        "id": "4rxCwlBPCUEb",
        "outputId": "7789eefa-fdc0-4896-972c-e8de8597c082"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " +  +  +  +  +  +  +  +  +  +  +  +  +  +  +  + \n",
            " +  +  +  +  + ▉ +  +  +  + ▉ +  +  +  +  + \n",
            " +  +  +  +  +  +  +  +  🎉  +  +  +  +  +  +  + \n",
            " +  +  +  +  +  +  + ▉ +  +  +  +  +  +  +  + \n",
            " +  +  +  +  +  +  +  +  +  +  +  +  +  +  +  + \n",
            " + ▉ +  +  +  +  +  +  +  +  +  +  +  +  +  + \n",
            " +  +  +  +  +  +  +  +  +  +  +  + ▉ +  +  + \n",
            " +  +  +  +  + ▉ +  +  +  +  +  +  +  +  + ▉\n",
            " +  +  + ▉ +  +  +  +  +  +  +  +  +  +  +  + \n",
            " +  +  +  +  +  +  +  +  +  +  +  +  +  +  +  + \n",
            " + ▉ +  +  +  +  +  +  + ▉ +  +  + ▉▉ + \n",
            " +  +  +  +  +  +  +  +  +  +  +  +  + ▉ +  + \n",
            " +  +  + ▉ +  +  +  +  +  +  +  +  +  +  +  + \n",
            " +  +  +  +  +  +  +  +  + ▉ +  +  +  +  +  + \n",
            " +  +  +  +  +  +  +  +  +  +  +  +  + ▉ +  + \n",
            " +  +  +  +  +  +  +  +  +  + ▉ +  +  +  +  + \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-51b7307094f5>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#1 sec wait to make it less jumpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0munprocessed_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideo_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Capturing\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# JS Camera and meidapipe operations per frame\n",
        "\n",
        "#Calling function for video feed\n",
        "video_stream()\n",
        "\n",
        "#Function call shorthand\n",
        "mp_hands = mp.solutions.hands\n",
        "\n",
        "while True:\n",
        "    #1 sec wait to make it less jumpy\n",
        "    time.sleep(2)\n",
        "\n",
        "    unprocessed_frame = video_frame(\"Capturing\", '')\n",
        "    #Will stop running if feed is closed\n",
        "    if not unprocessed_frame:\n",
        "        print(\"Program has been closed. Have a nice day!\")\n",
        "        break\n",
        "\n",
        "\n",
        "    #Processing frame:\n",
        "    # Takes js feed and makes it a BGR image\n",
        "    current_frame = js_to_image(unprocessed_frame[\"img\"])\n",
        "    #frame = cv2.flip(current_frame, 1) # Horizontal flip\n",
        "    #print(current_frame)\n",
        "\n",
        "\n",
        "    #meidapipe stuff (hand tracking):\n",
        "    # Sets parameters of hand tracking model to process frames as video, detect 1 hand, with a moderate amount of confidance\n",
        "    with mp_hands.Hands(\n",
        "        static_image_mode = False,\n",
        "        max_num_hands = 1,\n",
        "        min_detection_confidence = 0.8\n",
        "            ) as hands:\n",
        "\n",
        "        # .process Takes an RGB image (BGR2RGB converts it) and creates hand \"landmakrs\" for it\n",
        "        frame = hands.process(cv2.flip(cv2.cvtColor(current_frame, cv2.COLOR_BGR2RGB), 1))\n",
        "\n",
        "        # Restarts loop if no landmarks detected\n",
        "        if not frame.multi_hand_landmarks:\n",
        "            continue\n",
        "\n",
        "        \"\"\"\n",
        "        # Will only get x & y of right hand index finger\n",
        "        if frame.multi_handedness == \"Right\":\n",
        "        \"\"\"\n",
        "        # Looks throgh the hand landmarks and looks for an index finger\n",
        "        # Finds the x and y coordinates of it\n",
        "        for hand_landmarks in frame.multi_hand_landmarks:\n",
        "            x_cood = int(hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].x * grid_size)\n",
        "            y_cood = int(hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].y * grid_size)\n",
        "            #print(x_cood, y_cood)\n",
        "\n",
        "            #Takes those x and y coordinates and sends them off to the update_maze function\n",
        "            update_maze(y_cood, x_cood)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN5Pum/ST+bCMShWToicCEC",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}